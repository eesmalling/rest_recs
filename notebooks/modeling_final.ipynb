{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Dataset Recommender System - Data Wrangling and Modelling\n",
    "by Saran Liukasemsarn, Elliot Smalling and Sachin Sridhar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data Wrangling\n",
    "\n",
    "In the EDA portion of the projects we decided to filter the dataset to contain only restaurants in Canada. This abbreviated dataset is located [here](https://drive.google.com/open?id=1r5K6-7MWacaLjp25nlYL8DtazJ8aDh7E). Based on the results of the EDA and the design decisions made for the analysis, we perform data wrangling, the steps of which have been outlined below -\n",
    "1. Eliminate restaurants with a low number of reviews (for reliability of information)\n",
    "2. Eliminate users with a low number of restaurant reviews\n",
    "3. Perform one-hot encoding for users and restaurants\n",
    "4. Split the reviews into three datasets randomly: training, test, and holdout, such that every restaurant is in the training set and that every user is in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import copy\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has already been filtered based on geographical location (only restaurants in two states of Canada - Ontario and Quebec - have been selected) and basic data cleaning operations have been carried out on the datasets shared by Yelp. The modified (cleaned) versions of the three datasets have been imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the datasets\n",
    "business = pd.read_csv('cleaned_data/business.csv')\n",
    "review = pd.read_csv('cleaned_data/review.csv')\n",
    "user = pd.read_csv('cleaned_data/user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Excluding an unnecessary column from the three datasets\n",
    "if 'Unnamed: 0' in business.columns:\n",
    "    del business['Unnamed: 0']\n",
    "if 'Unnamed: 0' in review.columns:\n",
    "    del review['Unnamed: 0']\n",
    "if 'Unnamed: 0' in user.columns:\n",
    "    del user['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a table showing the number of users with n reviews for all n in the review dataset (Table showing number of users that make a particular number of reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of reviews (n)</th>\n",
       "      <th>number of users with n reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number of reviews (n)  number of users with n reviews\n",
       "0                      1                           56926\n",
       "1                      2                           19261\n",
       "2                      3                            9854\n",
       "3                      4                            6124\n",
       "4                      5                            3969\n",
       "5                      6                            2763\n",
       "6                      7                            2091\n",
       "7                      8                            1633\n",
       "8                      9                            1234\n",
       "9                     10                            1018"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of reviews for each user and sort these sizes\n",
    "review_user = review.groupby(['user_id']).size().sort_values()\n",
    "# make a new dataframe\n",
    "review_frame = pd.DataFrame(review_user.groupby(review_user).size())\n",
    "review_frame.columns = ['number of users with n reviews']\n",
    "review_frame['number of reviews (n)'] = review_frame.index\n",
    "review_frame = review_frame[['number of reviews (n)','number of users with n reviews']]\n",
    "review_frame = review_frame.reset_index(drop=True)\n",
    "review_frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of reviews (n)</th>\n",
       "      <th>number of users with n reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number of reviews (n)  number of users with n reviews\n",
       "249                    545                               1\n",
       "250                   2139                               1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_frame.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, it is evident that there are many users with very few reviews. These could lead to unreliable predictions due to lack of sufficient information, and hence, we will eliminate them. We will also remove restaurants with very few reviews. For example, if we have just two reviews for a restaurant, we cannot be sure that the sources of the two reviews are reliable.\n",
    "\n",
    "**Restaurants with fewer than 15 reviews and users with fewer than 50 reviews have been excluded from the analysis, in order to enhance reliability and improve the accuracy of our results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "review2 = (review.groupby('business_id').filter(lambda g: len(g) > 15))\n",
    "review2 = (review2.groupby('user_id').filter(lambda g: len(g) > 50)).copy(deep=True).reset_index(drop=True)\n",
    "review2_backup = review2.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a summary of the dataframe *review2*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users with more than 50 reviews (review2):  1073\n",
      "total # users (review2):                      1073\n",
      "total # restaurants (review2):                7345\n",
      "total # reviews (review2):                    103112\n"
     ]
    }
   ],
   "source": [
    "print('# users with more than 50 reviews (review2): ', np.sum(review2.groupby(['user_id']).size() > 50))\n",
    "print('total # users (review2):                     ', len(review2.groupby(['user_id'])))\n",
    "print('total # restaurants (review2):               ', len(review2.groupby(['business_id'])))\n",
    "print('total # reviews (review2):                   ', len(review2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of users with more than 50 reviews equals the total number of users in review2. Now, let's generate user2 and business2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # users (user2):                        1073\n",
      "total # restaurants (business2):              7345\n"
     ]
    }
   ],
   "source": [
    "# get all the users in review2\n",
    "list_users = list(review2['user_id'].unique())\n",
    "# get all the restaurants in review2\n",
    "list_restaurants = list(review2['business_id'].unique())\n",
    "user2 = user[(user['user_id']).isin(list_users)]\n",
    "business2 = business[(business['business_id']).isin(list_restaurants)]\n",
    "print('total # users (user2):                       ', len(user2))\n",
    "print('total # restaurants (business2):             ', len(business2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of users in *user2* equals the total number of users in *review2*. The total number of restaurants in *business2* also equals to the total number of restaurants in *review2*. \n",
    "\n",
    "**The next task is to split the data, and we start by permuting the data. The objective is to make sure that each user is present in every split and that the training set contains every restaurant in review2.** This must be done to ensure that we have some information about each user and that the matrix in Part 3 covers all the possibilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(9001)\n",
    "# permute the data\n",
    "review2 = review2_backup.copy(deep=True)\n",
    "permuted_index = np.random.permutation(review2.index)\n",
    "review2 = review2.reindex(permuted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a temporary column that will be used to split the data\n",
    "review2['temp'] = range(len(review2))\n",
    "\n",
    "# group by restaurant and rank them\n",
    "ranks_rest = review2.groupby('business_id')['temp'].rank(method='first')\n",
    "\n",
    "# delete temp variable which is no longer important\n",
    "del review2['temp']\n",
    "\n",
    "# split the data, part1 contains the first observation of each restaurant\n",
    "part1 = (review2[ranks_rest == 1]).copy(deep=True)\n",
    "# part 2 is the rest\n",
    "part2 = (review2[ranks_rest != 1]).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part2['temp'] = range(len(part2))\n",
    "\n",
    "# ranks assigned to observations according to order they appear in the dataframe (for each group)\n",
    "ranks_user = part2.groupby('user_id')['temp'].rank(method='first')\n",
    "\n",
    "# counts\n",
    "counts_user = part2['user_id'].map(part2.groupby('user_id').size())\n",
    "\n",
    "train_mask = (ranks_user/counts_user < 0.15)\n",
    "test_mask = (0.15 <= ranks_user/counts_user) & (ranks_user/counts_user < 0.3)\n",
    "holdout_mask = (0.3 <= ranks_user/counts_user)\n",
    "\n",
    "# delete the 'temp' variable -> it is no longer important\n",
    "del part2['temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the variables *user_id* and *restaurant_id* are categorical variables, we convert them into their biniarized forms (create indicator variables) for each value taken up by these two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split\n",
    "train_set = pd.concat([part1, part2[train_mask]], axis=0)\n",
    "train_set['type'] = 'train'\n",
    "test_set = (part2[test_mask]).copy(deep=True)\n",
    "test_set['type'] = 'test'\n",
    "holdout_set = (part2[holdout_mask]).copy(deep=True)\n",
    "holdout_set['type'] = 'holdout'\n",
    "\n",
    "review2 = pd.concat([train_set, test_set, holdout_set], axis=0)\n",
    "\n",
    "    \n",
    "# make dummy variables but keep original 'user_id' and 'business_id' in there, drop one binary variable of each type\n",
    "review2 = pd.concat([review2, pd.get_dummies(review2[['user_id','business_id']], drop_first=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = review2[review2['type'] == 'train']\n",
    "test_set = review2[review2['type'] == 'test']\n",
    "holdout_set = review2[review2['type'] == 'holdout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training set:  21154\n",
      "size of test set:      14331\n",
      "size of holdout set:   67627\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training</th>\n",
       "      <th>test</th>\n",
       "      <th>holdout</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--Qh8yKWAvIP4V4K8ZPfHA</th>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-B4Cf2XLkPr9qMlLPHJAlw</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-KVxkJDSTjtPGsamMDG92Q</th>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-KpEgEen1tj-jdjIS7uVOw</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-RCD8F7qbsLfzT3k1HtMxg</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        training  test  holdout\n",
       "user_id                                        \n",
       "--Qh8yKWAvIP4V4K8ZPfHA        38    27      124\n",
       "-B4Cf2XLkPr9qMlLPHJAlw        12     9       45\n",
       "-KVxkJDSTjtPGsamMDG92Q        17    11       52\n",
       "-KpEgEen1tj-jdjIS7uVOw        23     8       37\n",
       "-RCD8F7qbsLfzT3k1HtMxg        12     9       43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('size of training set: ', len(train_set))\n",
    "print('size of test set:     ', len(test_set))\n",
    "print('size of holdout set:  ', len(holdout_set))\n",
    "\n",
    "compare_data_sets = pd.DataFrame()\n",
    "compare_data_sets['training'] = train_set.groupby('user_id').size()\n",
    "compare_data_sets['test'] = test_set.groupby('user_id').size()\n",
    "compare_data_sets['holdout'] = holdout_set.groupby('user_id').size()\n",
    "\n",
    "compare_data_sets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make two observations from the outputs displayed above. First, we notice the split between the training, test and the hold-out datasets. Second, in the table displayed above, we find a description of how the reviews of each user have been split across the three datasets. It has been ensured that the reviews of a user are well represented in all the three datasets - the training, test and hold-out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique users:                            1073\n",
      "number of unique users in the training set:        1073\n",
      "number of unique users in the test set:            1073\n",
      "number of unique users in the holdout set:         1073\n",
      "number of unique restaurants:                      7345\n",
      "number of unique restaurants in the training set:  7345\n"
     ]
    }
   ],
   "source": [
    "print('number of unique users:                           ', len(review2['user_id'].unique()))\n",
    "print('number of unique users in the training set:       ', len(train_set['user_id'].unique()))\n",
    "print('number of unique users in the test set:           ', len(test_set['user_id'].unique()))\n",
    "print('number of unique users in the holdout set:        ', len(holdout_set['user_id'].unique()))\n",
    "print('number of unique restaurants:                     ', len(review2['business_id'].unique()))\n",
    "print('number of unique restaurants in the training set: ', len(train_set['business_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_x = train_set.copy(deep=True)\n",
    "test_set_x = test_set.copy(deep=True)\n",
    "holdout_set_x = holdout_set.copy(deep=True)\n",
    "\n",
    "for var in ['type','business_id', 'date', 'stars', 'user_id']:\n",
    "    if var in train_set_x.columns:\n",
    "        del train_set_x[var]\n",
    "    if var in test_set_x.columns:\n",
    "        del test_set_x[var]\n",
    "    if var in holdout_set_x.columns:\n",
    "        del holdout_set_x[var]\n",
    "\n",
    "train_set_y = train_set['stars']\n",
    "test_set_y = test_set['stars']\n",
    "holdout_set_y = holdout_set['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_-B4Cf2XLkPr9qMlLPHJAlw</th>\n",
       "      <th>user_id_-KVxkJDSTjtPGsamMDG92Q</th>\n",
       "      <th>user_id_-KpEgEen1tj-jdjIS7uVOw</th>\n",
       "      <th>user_id_-RCD8F7qbsLfzT3k1HtMxg</th>\n",
       "      <th>user_id_-_2h2cJlBOWAYrfplMU-Cg</th>\n",
       "      <th>user_id_-d2daWmftYumOaYpbD5D8Q</th>\n",
       "      <th>user_id_-dbWm5L_Ol2hZeLRoQOK7w</th>\n",
       "      <th>user_id_-fEe8XBeJ6pGLIeAyAWzfw</th>\n",
       "      <th>user_id_-hUgrj7Lzir3yLUYrMYQ4g</th>\n",
       "      <th>user_id_-m0KTRk0c901-4b-BN34Gg</th>\n",
       "      <th>...</th>\n",
       "      <th>business_id_zvtkeghW0Px5HY9QkJ4INw</th>\n",
       "      <th>business_id_zw4Legbcu018p5WcZ74iWA</th>\n",
       "      <th>business_id_zw74kL1IvT65yRvNLx5UxA</th>\n",
       "      <th>business_id_zwkif4XLEDqdEwEgTWLIVQ</th>\n",
       "      <th>business_id_zxJlg4XCHNoFy78WZPv89w</th>\n",
       "      <th>business_id_zy_NHTqtfSrfTGGPoqy4Mw</th>\n",
       "      <th>business_id_zyw5DjrRks7a8OhmBsgCQQ</th>\n",
       "      <th>business_id_zz3CqZhNx2rQ_Yp6zHze-A</th>\n",
       "      <th>business_id_zze6IysT7bJFS8gvi6fZ2A</th>\n",
       "      <th>business_id_zzlZJVkEhOzR2tJOLHcF2A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 8416 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id_-B4Cf2XLkPr9qMlLPHJAlw  user_id_-KVxkJDSTjtPGsamMDG92Q  \\\n",
       "2721                                0                               0   \n",
       "39119                               0                               0   \n",
       "\n",
       "       user_id_-KpEgEen1tj-jdjIS7uVOw  user_id_-RCD8F7qbsLfzT3k1HtMxg  \\\n",
       "2721                                0                               0   \n",
       "39119                               0                               0   \n",
       "\n",
       "       user_id_-_2h2cJlBOWAYrfplMU-Cg  user_id_-d2daWmftYumOaYpbD5D8Q  \\\n",
       "2721                                0                               0   \n",
       "39119                               0                               0   \n",
       "\n",
       "       user_id_-dbWm5L_Ol2hZeLRoQOK7w  user_id_-fEe8XBeJ6pGLIeAyAWzfw  \\\n",
       "2721                                0                               0   \n",
       "39119                               0                               0   \n",
       "\n",
       "       user_id_-hUgrj7Lzir3yLUYrMYQ4g  user_id_-m0KTRk0c901-4b-BN34Gg  \\\n",
       "2721                                0                               0   \n",
       "39119                               0                               0   \n",
       "\n",
       "                      ...                  business_id_zvtkeghW0Px5HY9QkJ4INw  \\\n",
       "2721                  ...                                                   0   \n",
       "39119                 ...                                                   0   \n",
       "\n",
       "       business_id_zw4Legbcu018p5WcZ74iWA  business_id_zw74kL1IvT65yRvNLx5UxA  \\\n",
       "2721                                    0                                   0   \n",
       "39119                                   0                                   0   \n",
       "\n",
       "       business_id_zwkif4XLEDqdEwEgTWLIVQ  business_id_zxJlg4XCHNoFy78WZPv89w  \\\n",
       "2721                                    0                                   0   \n",
       "39119                                   0                                   0   \n",
       "\n",
       "       business_id_zy_NHTqtfSrfTGGPoqy4Mw  business_id_zyw5DjrRks7a8OhmBsgCQQ  \\\n",
       "2721                                    0                                   0   \n",
       "39119                                   0                                   0   \n",
       "\n",
       "       business_id_zz3CqZhNx2rQ_Yp6zHze-A  business_id_zze6IysT7bJFS8gvi6fZ2A  \\\n",
       "2721                                    0                                   0   \n",
       "39119                                   0                                   0   \n",
       "\n",
       "       business_id_zzlZJVkEhOzR2tJOLHcF2A  \n",
       "2721                                    0  \n",
       "39119                                   0  \n",
       "\n",
       "[2 rows x 8416 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a view of the predictors in the training dataset\n",
    "# These are the binarized versions of each user_id and restaurant_id present in the dataset\n",
    "train_set_x.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2(a): Creating a Basline Linear Regression Model\n",
    "In the first part of our analysis, we create a baseline estimate of the ratings.\n",
    "#### We fit the baseline linear regression model, represented mathematically as $\\hat{Y}_{um} = \\hat{\\mu} + \\hat{\\theta}_u + \\hat{\\gamma}_m$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the linear baseline regression model\n",
    "regress1 = LinearRegression()\n",
    "regress1.fit(train_set_x, train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score 1:     -0.130286650544\n"
     ]
    }
   ],
   "source": [
    "print('test score 1:    ', regress1.score(test_set_x, test_set_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice a poor score for the Test/Validation $R^2$, and hence performed Regulzarized Regression (with Lasso)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2(b): Creating a Regularized Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=[1e-05, 0.0001, 0.001, 0.005, 1, 5, 10, 50, 100, 500, 1000],\n",
       "    copy_X=True, cv=10, eps=0.001, fit_intercept=True, max_iter=1000,\n",
       "    n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
       "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas = [.00001, .0001, .001,.005,1,5,10,50,100,500,1000]\n",
    "regress2 = LassoCV(cv=10, alphas=lambdas)\n",
    "regress2.fit(train_set_x, train_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score 2:     0.0993635027725\n"
     ]
    }
   ],
   "source": [
    "print('test score 2:    ', regress2.score(test_set_x, test_set_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to the Linear Regression Model without Regularization, we observe a significant improvement in the $R^2$ value on the test dataset. \n",
    "\n",
    "**The $R^2$ of the Lasso Regularized Model on the test dataset is 0.1**\n",
    "\n",
    "**As a consequence of improved performance of the Lasso Regularized Regression Model, we choose this as our baseline, and perform all subsequent checks/comparisons with respect to this model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regress2.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the residuals obtained from the regression model in the next stage of our analysis -\n",
    "\n",
    "### Part 3: Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to create a matrix, which contains residuals from the baseline model on the training dataset. The matrix will have the list of users along its rows and the list of restaurants along its columns.\n",
    "\n",
    "This will be obtained by pivoting our existing dataframe appropriately. Also, the **matrix is sparse** i.e. most of the matrix values do not exist. We intially fill them in using zeros, and our goal is to find the *'best guess'* for these values through Matrix Factorization using Alternating Least Squares.\n",
    "\n",
    "In order to perform computations in subsequent steps, we will need to replace the null values. Based on consideration of the Weight Matrix $W$ (explained below), we set these null values to 0. Setting the Null values to zero will not conflict with the calculated residuals, since none of the training residuals has been found to be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the predicted values for the training dataset from the lasso regualized model\n",
    "y_hat = regress2.predict(train_set_x)\n",
    "y_hat_test = regress2.predict(test_set_x)\n",
    "\n",
    "# Residual = Observed Value - Predicted value\n",
    "resid = train_set_y - y_hat\n",
    "resid_test = test_set_y - y_hat_test\n",
    "\n",
    "# Now, merge this array with X_train to get a dataset containing all the predictors and\n",
    "# the corresponding residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21154, 8421)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_resid = train_set.copy(deep = True) \n",
    "train_set_resid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>user_id</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id_-B4Cf2XLkPr9qMlLPHJAlw</th>\n",
       "      <th>user_id_-KVxkJDSTjtPGsamMDG92Q</th>\n",
       "      <th>user_id_-KpEgEen1tj-jdjIS7uVOw</th>\n",
       "      <th>user_id_-RCD8F7qbsLfzT3k1HtMxg</th>\n",
       "      <th>user_id_-_2h2cJlBOWAYrfplMU-Cg</th>\n",
       "      <th>...</th>\n",
       "      <th>business_id_zw4Legbcu018p5WcZ74iWA</th>\n",
       "      <th>business_id_zw74kL1IvT65yRvNLx5UxA</th>\n",
       "      <th>business_id_zwkif4XLEDqdEwEgTWLIVQ</th>\n",
       "      <th>business_id_zxJlg4XCHNoFy78WZPv89w</th>\n",
       "      <th>business_id_zy_NHTqtfSrfTGGPoqy4Mw</th>\n",
       "      <th>business_id_zyw5DjrRks7a8OhmBsgCQQ</th>\n",
       "      <th>business_id_zz3CqZhNx2rQ_Yp6zHze-A</th>\n",
       "      <th>business_id_zze6IysT7bJFS8gvi6fZ2A</th>\n",
       "      <th>business_id_zzlZJVkEhOzR2tJOLHcF2A</th>\n",
       "      <th>residuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>bRmb81XDG3E2SOHARBLTog</td>\n",
       "      <td>2010-08-15</td>\n",
       "      <td>4</td>\n",
       "      <td>oBc0gQ4RpFrqzpNlH6_epA</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39119</th>\n",
       "      <td>X_Pg8SvGGYhCxwWRkrUv3Q</td>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>4</td>\n",
       "      <td>dT1jqOZrFUmY4m4o37c8rw</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.279164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49343</th>\n",
       "      <td>8xI4hJ3nS4avEoo_l62dkw</td>\n",
       "      <td>2010-09-26</td>\n",
       "      <td>3</td>\n",
       "      <td>qOdmye8UQdqloVNE059PkQ</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.885521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83548</th>\n",
       "      <td>q9_gLvTNf11etVxbH7JY0Q</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>4</td>\n",
       "      <td>Jm5h-bDATqRMWs3VahkFPg</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.403760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52893</th>\n",
       "      <td>J9BmILDpV1Pr3GKU9XhjTQ</td>\n",
       "      <td>2008-11-27</td>\n",
       "      <td>4</td>\n",
       "      <td>Yp7_GeD6KTRoo4Nteqv4SA</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8422 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  business_id        date  stars                 user_id  \\\n",
       "2721   bRmb81XDG3E2SOHARBLTog  2010-08-15      4  oBc0gQ4RpFrqzpNlH6_epA   \n",
       "39119  X_Pg8SvGGYhCxwWRkrUv3Q  2016-01-24      4  dT1jqOZrFUmY4m4o37c8rw   \n",
       "49343  8xI4hJ3nS4avEoo_l62dkw  2010-09-26      3  qOdmye8UQdqloVNE059PkQ   \n",
       "83548  q9_gLvTNf11etVxbH7JY0Q  2017-01-26      4  Jm5h-bDATqRMWs3VahkFPg   \n",
       "52893  J9BmILDpV1Pr3GKU9XhjTQ  2008-11-27      4  Yp7_GeD6KTRoo4Nteqv4SA   \n",
       "\n",
       "        type  user_id_-B4Cf2XLkPr9qMlLPHJAlw  user_id_-KVxkJDSTjtPGsamMDG92Q  \\\n",
       "2721   train                               0                               0   \n",
       "39119  train                               0                               0   \n",
       "49343  train                               0                               0   \n",
       "83548  train                               0                               0   \n",
       "52893  train                               0                               0   \n",
       "\n",
       "       user_id_-KpEgEen1tj-jdjIS7uVOw  user_id_-RCD8F7qbsLfzT3k1HtMxg  \\\n",
       "2721                                0                               0   \n",
       "39119                               0                               0   \n",
       "49343                               0                               0   \n",
       "83548                               0                               0   \n",
       "52893                               0                               0   \n",
       "\n",
       "       user_id_-_2h2cJlBOWAYrfplMU-Cg    ...      \\\n",
       "2721                                0    ...       \n",
       "39119                               0    ...       \n",
       "49343                               0    ...       \n",
       "83548                               0    ...       \n",
       "52893                               0    ...       \n",
       "\n",
       "       business_id_zw4Legbcu018p5WcZ74iWA  business_id_zw74kL1IvT65yRvNLx5UxA  \\\n",
       "2721                                    0                                   0   \n",
       "39119                                   0                                   0   \n",
       "49343                                   0                                   0   \n",
       "83548                                   0                                   0   \n",
       "52893                                   0                                   0   \n",
       "\n",
       "       business_id_zwkif4XLEDqdEwEgTWLIVQ  business_id_zxJlg4XCHNoFy78WZPv89w  \\\n",
       "2721                                    0                                   0   \n",
       "39119                                   0                                   0   \n",
       "49343                                   0                                   0   \n",
       "83548                                   0                                   0   \n",
       "52893                                   0                                   0   \n",
       "\n",
       "       business_id_zy_NHTqtfSrfTGGPoqy4Mw  business_id_zyw5DjrRks7a8OhmBsgCQQ  \\\n",
       "2721                                    0                                   0   \n",
       "39119                                   0                                   0   \n",
       "49343                                   0                                   0   \n",
       "83548                                   0                                   0   \n",
       "52893                                   0                                   0   \n",
       "\n",
       "       business_id_zz3CqZhNx2rQ_Yp6zHze-A  business_id_zze6IysT7bJFS8gvi6fZ2A  \\\n",
       "2721                                    0                                   0   \n",
       "39119                                   0                                   0   \n",
       "49343                                   0                                   0   \n",
       "83548                                   0                                   0   \n",
       "52893                                   0                                   0   \n",
       "\n",
       "       business_id_zzlZJVkEhOzR2tJOLHcF2A  residuals  \n",
       "2721                                    0   0.455356  \n",
       "39119                                   0   0.279164  \n",
       "49343                                   0  -0.885521  \n",
       "83548                                   0  -0.403760  \n",
       "52893                                   0   0.392325  \n",
       "\n",
       "[5 rows x 8422 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Including the additional column to the dataframe\n",
    "train_set_resid['residuals'] = resid\n",
    "train_set_resid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21154, 8422)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_resid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set_resid = test_set.copy(deep = True) \n",
    "test_set_resid['residuals'] = resid_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Before we pivot the data, we have ensured that the user_id and business_id combinedly describe the level of the table (implying that a person does not review the same restaurant multiple times).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum number of reviews for a user-restaurant pair:  1\n"
     ]
    }
   ],
   "source": [
    "# Check if any user has reviewed a restaurant more than once\n",
    "print('maximum number of reviews for a user-restaurant pair: ', max(train_set_resid.groupby(['user_id', 'business_id']).size().groupby(level=0).max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>business_id</th>\n",
       "      <th>--6MefnULPED_I942VcFNA</th>\n",
       "      <th>--DaPTJW3-tB1vP-PfdTEg</th>\n",
       "      <th>--SrzpvFLwP_YFwB_Cetow</th>\n",
       "      <th>-0CTrPQNiSyClxhdO4HSDQ</th>\n",
       "      <th>-0DET7VdEQOJVJ_v6klEug</th>\n",
       "      <th>-0NhdsDJsdarxyDPR523ZQ</th>\n",
       "      <th>-0NrB58jqKqJfuUCDupcsw</th>\n",
       "      <th>-0mm8pqBSIOYZQHeo8XnkA</th>\n",
       "      <th>-1xuC540Nycht_iWFeJ-dw</th>\n",
       "      <th>-25X5v1q3WU6s-craJSvTw</th>\n",
       "      <th>...</th>\n",
       "      <th>zvtkeghW0Px5HY9QkJ4INw</th>\n",
       "      <th>zw4Legbcu018p5WcZ74iWA</th>\n",
       "      <th>zw74kL1IvT65yRvNLx5UxA</th>\n",
       "      <th>zwkif4XLEDqdEwEgTWLIVQ</th>\n",
       "      <th>zxJlg4XCHNoFy78WZPv89w</th>\n",
       "      <th>zy_NHTqtfSrfTGGPoqy4Mw</th>\n",
       "      <th>zyw5DjrRks7a8OhmBsgCQQ</th>\n",
       "      <th>zz3CqZhNx2rQ_Yp6zHze-A</th>\n",
       "      <th>zze6IysT7bJFS8gvi6fZ2A</th>\n",
       "      <th>zzlZJVkEhOzR2tJOLHcF2A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>--Qh8yKWAvIP4V4K8ZPfHA</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-B4Cf2XLkPr9qMlLPHJAlw</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-KVxkJDSTjtPGsamMDG92Q</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-KpEgEen1tj-jdjIS7uVOw</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-RCD8F7qbsLfzT3k1HtMxg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "business_id             --6MefnULPED_I942VcFNA  --DaPTJW3-tB1vP-PfdTEg  \\\n",
       "user_id                                                                  \n",
       "--Qh8yKWAvIP4V4K8ZPfHA                     0.0                     0.0   \n",
       "-B4Cf2XLkPr9qMlLPHJAlw                     0.0                     0.0   \n",
       "-KVxkJDSTjtPGsamMDG92Q                     0.0                     0.0   \n",
       "-KpEgEen1tj-jdjIS7uVOw                     0.0                     0.0   \n",
       "-RCD8F7qbsLfzT3k1HtMxg                     0.0                     0.0   \n",
       "\n",
       "business_id             --SrzpvFLwP_YFwB_Cetow  -0CTrPQNiSyClxhdO4HSDQ  \\\n",
       "user_id                                                                  \n",
       "--Qh8yKWAvIP4V4K8ZPfHA                     0.0                     0.0   \n",
       "-B4Cf2XLkPr9qMlLPHJAlw                     0.0                     0.0   \n",
       "-KVxkJDSTjtPGsamMDG92Q                     0.0                     0.0   \n",
       "-KpEgEen1tj-jdjIS7uVOw                     0.0                     0.0   \n",
       "-RCD8F7qbsLfzT3k1HtMxg                     0.0                     0.0   \n",
       "\n",
       "business_id             -0DET7VdEQOJVJ_v6klEug  -0NhdsDJsdarxyDPR523ZQ  \\\n",
       "user_id                                                                  \n",
       "--Qh8yKWAvIP4V4K8ZPfHA                     0.0                     0.0   \n",
       "-B4Cf2XLkPr9qMlLPHJAlw                     0.0                     0.0   \n",
       "-KVxkJDSTjtPGsamMDG92Q                     0.0                     0.0   \n",
       "-KpEgEen1tj-jdjIS7uVOw                     0.0                     0.0   \n",
       "-RCD8F7qbsLfzT3k1HtMxg                     0.0                     0.0   \n",
       "\n",
       "business_id             -0NrB58jqKqJfuUCDupcsw  -0mm8pqBSIOYZQHeo8XnkA  \\\n",
       "user_id                                                                  \n",
       "--Qh8yKWAvIP4V4K8ZPfHA                     0.0                     0.0   \n",
       "-B4Cf2XLkPr9qMlLPHJAlw                     0.0                     0.0   \n",
       "-KVxkJDSTjtPGsamMDG92Q                     0.0                     0.0   \n",
       "-KpEgEen1tj-jdjIS7uVOw                     0.0                     0.0   \n",
       "-RCD8F7qbsLfzT3k1HtMxg                     0.0                     0.0   \n",
       "\n",
       "business_id             -1xuC540Nycht_iWFeJ-dw  -25X5v1q3WU6s-craJSvTw  \\\n",
       "user_id                                                                  \n",
       "--Qh8yKWAvIP4V4K8ZPfHA                     0.0                     0.0   \n",
       "-B4Cf2XLkPr9qMlLPHJAlw                     0.0                     0.0   \n",
       "-KVxkJDSTjtPGsamMDG92Q                     0.0                     0.0   \n",
       "-KpEgEen1tj-jdjIS7uVOw                     0.0                     0.0   \n",
       "-RCD8F7qbsLfzT3k1HtMxg                     0.0                     0.0   \n",
       "\n",
       "business_id                      ...            zvtkeghW0Px5HY9QkJ4INw  \\\n",
       "user_id                          ...                                     \n",
       "--Qh8yKWAvIP4V4K8ZPfHA           ...                               0.0   \n",
       "-B4Cf2XLkPr9qMlLPHJAlw           ...                               0.0   \n",
       "-KVxkJDSTjtPGsamMDG92Q           ...                               0.0   \n",
       "-KpEgEen1tj-jdjIS7uVOw           ...                               0.0   \n",
       "-RCD8F7qbsLfzT3k1HtMxg           ...                               0.0   \n",
       "\n",
       "business_id             zw4Legbcu018p5WcZ74iWA  zw74kL1IvT65yRvNLx5UxA  \\\n",
       "user_id                                                                  \n",
       "--Qh8yKWAvIP4V4K8ZPfHA                     0.0                     0.0   \n",
       "-B4Cf2XLkPr9qMlLPHJAlw                     0.0                     0.0   \n",
       "-KVxkJDSTjtPGsamMDG92Q                     0.0                     0.0   \n",
       "-KpEgEen1tj-jdjIS7uVOw                     0.0                     0.0   \n",
       "-RCD8F7qbsLfzT3k1HtMxg                     0.0                     0.0   \n",
       "\n",
       "business_id             zwkif4XLEDqdEwEgTWLIVQ  zxJlg4XCHNoFy78WZPv89w  \\\n",
       "user_id                                                                  \n",
       "--Qh8yKWAvIP4V4K8ZPfHA                     0.0                     0.0   \n",
       "-B4Cf2XLkPr9qMlLPHJAlw                     0.0                     0.0   \n",
       "-KVxkJDSTjtPGsamMDG92Q                     0.0                     0.0   \n",
       "-KpEgEen1tj-jdjIS7uVOw                     0.0                     0.0   \n",
       "-RCD8F7qbsLfzT3k1HtMxg                     0.0                     0.0   \n",
       "\n",
       "business_id             zy_NHTqtfSrfTGGPoqy4Mw  zyw5DjrRks7a8OhmBsgCQQ  \\\n",
       "user_id                                                                  \n",
       "--Qh8yKWAvIP4V4K8ZPfHA                     0.0                     0.0   \n",
       "-B4Cf2XLkPr9qMlLPHJAlw                     0.0                     0.0   \n",
       "-KVxkJDSTjtPGsamMDG92Q                     0.0                     0.0   \n",
       "-KpEgEen1tj-jdjIS7uVOw                     0.0                     0.0   \n",
       "-RCD8F7qbsLfzT3k1HtMxg                     0.0                     0.0   \n",
       "\n",
       "business_id             zz3CqZhNx2rQ_Yp6zHze-A  zze6IysT7bJFS8gvi6fZ2A  \\\n",
       "user_id                                                                  \n",
       "--Qh8yKWAvIP4V4K8ZPfHA                     0.0                     0.0   \n",
       "-B4Cf2XLkPr9qMlLPHJAlw                     0.0                     0.0   \n",
       "-KVxkJDSTjtPGsamMDG92Q                     0.0                     0.0   \n",
       "-KpEgEen1tj-jdjIS7uVOw                     0.0                     0.0   \n",
       "-RCD8F7qbsLfzT3k1HtMxg                     0.0                     0.0   \n",
       "\n",
       "business_id             zzlZJVkEhOzR2tJOLHcF2A  \n",
       "user_id                                         \n",
       "--Qh8yKWAvIP4V4K8ZPfHA                     0.0  \n",
       "-B4Cf2XLkPr9qMlLPHJAlw                     0.0  \n",
       "-KVxkJDSTjtPGsamMDG92Q                     0.0  \n",
       "-KpEgEen1tj-jdjIS7uVOw                     0.0  \n",
       "-RCD8F7qbsLfzT3k1HtMxg                     0.0  \n",
       "\n",
       "[5 rows x 7345 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we pivot this dataframe into the required format\n",
    "# Users along rows, restaurants along columns, residuals as entries\n",
    "df_review = train_set_resid.pivot(index = 'user_id', columns ='business_id', values = 'residuals').fillna(0)\n",
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting the pivoted dataframe into a numpy matrix:\n",
    "df_review_matrix = df_review.as_matrix() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1073, 7345)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started out with 1073 users and 7345 restaurants in the training dataset, so the dimensions of the matrix seem to be correct.\n",
    "\n",
    "We setup to apply the **Alternating Least Squares Regression** method to accomplish matrix factorization. Our objective is to minimize the following loss function:\n",
    "\n",
    "$\\sum_{u,m}(Y_{u,m} - \\mu -\\bar{\\theta}.I_{u} - \\bar{\\gamma}I_m-\\bar{q}_m^T\\bar{p}_u)^2 + \\alpha(\\theta^2 + \\gamma_m^2 + ||\\bar{q}_m||^2 + ||\\bar{p}_u||^2)$\n",
    "\n",
    "A brief description of the methodology has been shown below -\n",
    "\n",
    "We perform the process of validation in order to tune the parameters alpha (penalty) and the number of latent factors in the matrix. Due to extremely large run-times, only two combinations of the validations have been shown below, however, multiple other combinations of *alpha* and number of latent factors have been explored/checked. \n",
    "\n",
    "We arrive at the optimal values of *alpha* and number of latent factors to be considered in the process of factorization by computing the sum of squared errors on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Performing Alternating Least Squares Regression\n",
    "\n",
    "#Setting things up:\n",
    "# We define Matrix Q as the matrix of residuals\n",
    "Q = df_review_matrix.copy()\n",
    "\n",
    "# Based on Q, we define W as follows -\n",
    "# Where the initial entires were non-zero, fill-in 1, and where the initial entires were 0,\n",
    "# fill in 0\n",
    "W = Q!=0\n",
    "W[W == True] = 1\n",
    "W[W == False] = 0\n",
    "W = W.astype(np.float64, copy=False)\n",
    "m, n = Q.shape\n",
    "n_iterations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def get_error(Q, X, Y, W):\n",
    "#    return np.sum((W * (Q - np.dot(X, Y)))**2)\n",
    "\n",
    "#list_lambda_ = [0.05, 0.5, 5, 50]\n",
    "#list_n_factors = [4,10]\n",
    "#train_error = []\n",
    "#test_sse = []\n",
    "\n",
    "#for lambda_ in list_lambda_:\n",
    "#    for n_factors in list_n_factors:\n",
    "#        X = np.random.randn(m, n_factors) \n",
    "#        Y = np.random.randn(n_factors, n)\n",
    "#        weighted_errors = []\n",
    "#        print('********************')\n",
    "#        print('lambda:    ', lambda_)\n",
    "#        print('n_factors: ', n_factors)\n",
    "#        for ii in range(n_iterations):\n",
    "#            for u, Wu in enumerate(W):\n",
    "#                X[u] = np.linalg.solve(np.dot(Y, np.dot(np.diag(Wu), Y.T)) + lambda_ * np.eye(n_factors),\n",
    "#                               np.dot(Y, np.dot(np.diag(Wu), Q[u].T))).T\n",
    "#            for i, Wi in enumerate(W.T):\n",
    "#                Y[:,i] = np.linalg.solve(np.dot(X.T, np.dot(np.diag(Wi), X)) + lambda_ * np.eye(n_factors),\n",
    "#                                 np.dot(X.T, np.dot(np.diag(Wi), Q[:, i])))\n",
    "#            weighted_errors.append(get_error(Q, X, Y, W))\n",
    "#            print('iteration '+ str(ii+1) + ' is completed')\n",
    "#        weighted_Q_hat = np.dot(X,Y)\n",
    "#        # training error\n",
    "#        train_error.append(((lambda_, n_factors),weighted_errors))\n",
    "#        preds_df = pd.DataFrame(weighted_Q_hat, columns = df_review.columns)\n",
    "#        user_ids = np.array(df_review.index)\n",
    "#        preds_df['user_id'] = user_ids\n",
    "#        user_business_residuals = pd.melt(preds_df,id_vars = ['user_id'],value_vars = df_review.columns)\n",
    "#        test_data = test_set_resid.copy(deep=True)\n",
    "#        test_subset = test_data[['business_id','user_id','residuals']]\n",
    "#        result_test = pd.merge(test_subset,user_business_residuals, on = ['user_id','business_id'], how = 'inner')\n",
    "#        result_test['resid_of_resid'] = result_test['residuals'] - result_test['value']\n",
    "#        test_sse.append(((lambda_, n_factors),np.sum(result_test['resid_of_resid']**2)))\n",
    "        \n",
    "#validation_results = pd.DataFrame(test_sse)\n",
    "#validation_results.columns = ['lambda, n_factors', 'sum of squared errors']\n",
    "#validation_results.to_csv('Val_Scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>n_factors</th>\n",
       "      <th>sum of squared errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>24192.03429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>21338.07873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>19508.64591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>16860.38679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4</td>\n",
       "      <td>13330.57669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.00</td>\n",
       "      <td>10</td>\n",
       "      <td>13275.59727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50.00</td>\n",
       "      <td>4</td>\n",
       "      <td>13215.75947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50.00</td>\n",
       "      <td>10</td>\n",
       "      <td>13215.75947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lambda  n_factors  sum of squared errors\n",
       "0    0.05          4            24192.03429\n",
       "1    0.05         10            21338.07873\n",
       "2    0.50          4            19508.64591\n",
       "3    0.50         10            16860.38679\n",
       "4    5.00          4            13330.57669\n",
       "5    5.00         10            13275.59727\n",
       "6   50.00          4            13215.75947\n",
       "7   50.00         10            13215.75947"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_scores = pd.read_csv('Val_Scores.csv')\n",
    "val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "lambda:     50\n",
      "n_factors:  4\n",
      "iteration 1 is completed\n",
      "iteration 2 is completed\n",
      "iteration 3 is completed\n",
      "iteration 4 is completed\n",
      "iteration 5 is completed\n"
     ]
    }
   ],
   "source": [
    "best_lambda_ = 50\n",
    "best_n_factors = 4\n",
    "X = np.random.randn(m, best_n_factors) \n",
    "Y = np.random.randn(best_n_factors, n)\n",
    "print('********************')\n",
    "print('lambda:    ', best_lambda_)\n",
    "print('n_factors: ', best_n_factors)\n",
    "for ii in range(n_iterations):\n",
    "    for u, Wu in enumerate(W):\n",
    "        X[u] = np.linalg.solve(np.dot(Y, np.dot(np.diag(Wu), Y.T)) + best_lambda_ * np.eye(best_n_factors),\n",
    "                        np.dot(Y, np.dot(np.diag(Wu), Q[u].T))).T\n",
    "    for i, Wi in enumerate(W.T):\n",
    "        Y[:,i] = np.linalg.solve(np.dot(X.T, np.dot(np.diag(Wi), X)) + best_lambda_ * np.eye(best_n_factors),\n",
    "                         np.dot(X.T, np.dot(np.diag(Wi), Q[:, i])))\n",
    "    print('iteration '+ str(ii+1) + ' is completed')\n",
    "weighted_Q_hat = np.dot(X,Y)\n",
    "preds_df = pd.DataFrame(weighted_Q_hat, columns = df_review.columns)\n",
    "user_ids = np.array(df_review.index)\n",
    "preds_df['user_id'] = user_ids\n",
    "user_business_residuals = pd.melt(preds_df,id_vars = ['user_id'],value_vars = df_review.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>residuals_from_linear_regr</th>\n",
       "      <th>residuals_from_mat_factrz</th>\n",
       "      <th>resid_of_resid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bRmb81XDG3E2SOHARBLTog</td>\n",
       "      <td>oBc0gQ4RpFrqzpNlH6_epA</td>\n",
       "      <td>0.455356</td>\n",
       "      <td>9.933523e-17</td>\n",
       "      <td>0.455356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_Pg8SvGGYhCxwWRkrUv3Q</td>\n",
       "      <td>dT1jqOZrFUmY4m4o37c8rw</td>\n",
       "      <td>0.279164</td>\n",
       "      <td>-2.293740e-19</td>\n",
       "      <td>0.279164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8xI4hJ3nS4avEoo_l62dkw</td>\n",
       "      <td>qOdmye8UQdqloVNE059PkQ</td>\n",
       "      <td>-0.885521</td>\n",
       "      <td>-1.049530e-17</td>\n",
       "      <td>-0.885521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q9_gLvTNf11etVxbH7JY0Q</td>\n",
       "      <td>Jm5h-bDATqRMWs3VahkFPg</td>\n",
       "      <td>-0.403760</td>\n",
       "      <td>-1.918724e-17</td>\n",
       "      <td>-0.403760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J9BmILDpV1Pr3GKU9XhjTQ</td>\n",
       "      <td>Yp7_GeD6KTRoo4Nteqv4SA</td>\n",
       "      <td>0.392325</td>\n",
       "      <td>1.714463e-18</td>\n",
       "      <td>0.392325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                 user_id  residuals_from_linear_regr  \\\n",
       "0  bRmb81XDG3E2SOHARBLTog  oBc0gQ4RpFrqzpNlH6_epA                    0.455356   \n",
       "1  X_Pg8SvGGYhCxwWRkrUv3Q  dT1jqOZrFUmY4m4o37c8rw                    0.279164   \n",
       "2  8xI4hJ3nS4avEoo_l62dkw  qOdmye8UQdqloVNE059PkQ                   -0.885521   \n",
       "3  q9_gLvTNf11etVxbH7JY0Q  Jm5h-bDATqRMWs3VahkFPg                   -0.403760   \n",
       "4  J9BmILDpV1Pr3GKU9XhjTQ  Yp7_GeD6KTRoo4Nteqv4SA                    0.392325   \n",
       "\n",
       "   residuals_from_mat_factrz  resid_of_resid  \n",
       "0               9.933523e-17        0.455356  \n",
       "1              -2.293740e-19        0.279164  \n",
       "2              -1.049530e-17       -0.885521  \n",
       "3              -1.918724e-17       -0.403760  \n",
       "4               1.714463e-18        0.392325  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_set_resid.copy(deep=True)\n",
    "train_subset = train_data[['business_id','user_id','residuals']]\n",
    "result_train = pd.merge(train_subset,user_business_residuals, on = ['user_id','business_id'], how = 'inner')\n",
    "result_train['resid_of_resid'] = result_train['residuals'] - result_train['value']\n",
    "result_train = result_train.rename(columns={'value': 'residuals_from_mat_factrz', \n",
    "                        'residuals': 'residuals_from_linear_regr'})\n",
    "\n",
    "result_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>residuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>bRmb81XDG3E2SOHARBLTog</td>\n",
       "      <td>oBc0gQ4RpFrqzpNlH6_epA</td>\n",
       "      <td>0.455356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39119</th>\n",
       "      <td>X_Pg8SvGGYhCxwWRkrUv3Q</td>\n",
       "      <td>dT1jqOZrFUmY4m4o37c8rw</td>\n",
       "      <td>0.279164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49343</th>\n",
       "      <td>8xI4hJ3nS4avEoo_l62dkw</td>\n",
       "      <td>qOdmye8UQdqloVNE059PkQ</td>\n",
       "      <td>-0.885521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83548</th>\n",
       "      <td>q9_gLvTNf11etVxbH7JY0Q</td>\n",
       "      <td>Jm5h-bDATqRMWs3VahkFPg</td>\n",
       "      <td>-0.403760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52893</th>\n",
       "      <td>J9BmILDpV1Pr3GKU9XhjTQ</td>\n",
       "      <td>Yp7_GeD6KTRoo4Nteqv4SA</td>\n",
       "      <td>0.392325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  business_id                 user_id  residuals\n",
       "2721   bRmb81XDG3E2SOHARBLTog  oBc0gQ4RpFrqzpNlH6_epA   0.455356\n",
       "39119  X_Pg8SvGGYhCxwWRkrUv3Q  dT1jqOZrFUmY4m4o37c8rw   0.279164\n",
       "49343  8xI4hJ3nS4avEoo_l62dkw  qOdmye8UQdqloVNE059PkQ  -0.885521\n",
       "83548  q9_gLvTNf11etVxbH7JY0Q  Jm5h-bDATqRMWs3VahkFPg  -0.403760\n",
       "52893  J9BmILDpV1Pr3GKU9XhjTQ  Yp7_GeD6KTRoo4Nteqv4SA   0.392325"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_train.to_csv('training_residuals_of_residuals.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Attempting Other Modelling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we combine all the datasets, along with the residuals from the matrix factorization stage of the model. We also create several variables: day of the week the review was written, month the review was written, length of time the user was active on Yelp when review was written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'user_id', 'residuals_from_linear_regr',\n",
       "       'residuals_from_mat_factrz', 'resid_of_resid', 'city', 'state',\n",
       "       'latitude', 'longitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user.yelping_since = pd.to_datetime(user.yelping_since)\n",
    "#review.date = pd.to_datetime(review.date)\n",
    "#review['day'] = review.date.dt.weekday_name\n",
    "#review['month'] = review.date.dt.strftime('%B')\n",
    "#review = review.merge(user[['user_id','yelping_since']], how='left')\n",
    "#review['time_yelping'] = (review.date-review.yelping_since).dt.days\n",
    "#review.time_yelping[review.time_yelping < 1] = 1\n",
    "#review['log_time_yelping'] = np.log(review.time_yelping)\n",
    "#review['log_time_yelping2'] = review.log_time_yelping**2\n",
    "resids = result_train\n",
    "#resids = resids.merge(review, how='left')\n",
    "resids = resids.merge(business[['business_id','city','state','latitude','longitude']], how='left')\n",
    "resids.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the combinations of variables below, we fit a regular regression, a ridge regression, and a random forest regression as some models may be better suited to certain types of problems. We then perform 10-fold cross validation to assess how well the model woud perform out of sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: day and month that the review was written, and time user was active on Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format data\n",
    "#x_train = pd.get_dummies(resids[['day','month']]).iloc[:,1:18]\n",
    "#x_train['log_time_yelping'] = resids.log_time_yelping\n",
    "#x_train['log_time_yelping2'] = resids.log_time_yelping2\n",
    "#y_train = resids.resid_of_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple linear regression\n",
    "#lmdl = LinearRegression()\n",
    "#lmdl.fit(x_train, y_train)\n",
    "#print(\"10-fold CV R2:\", cross_val_score(lmdl, x_train, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ridge regression\n",
    "#rmdl = RidgeCV()\n",
    "#rmdl.fit(x_train, y_train)\n",
    "#print(\"10-fold CV R2:\", cross_val_score(rmdl, x_train, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random forest regression\n",
    "#depths = [2,3,5,7,10]\n",
    "#for i in depths:\n",
    "#    fmdl = RandomForestRegressor(n_estimators=100, max_features='sqrt', max_depth=i)\n",
    "#    fmdl.fit(x_train, y_train)\n",
    "#    print(\"10-fold CV R2, depth\", i, \":\", cross_val_score(fmdl, x_train, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: restaurant cities as factor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format data\n",
    "#x_train = pd.get_dummies(resids['city']).iloc[:,1:]\n",
    "#y_train = resids.resid_of_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple linear regression\n",
    "#lmdl = LinearRegression()\n",
    "#lmdl.fit(x_train, y_train)\n",
    "#print(\"10-fold CV R2:\", cross_val_score(lmdl, x_train, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ridge regression\n",
    "#rmdl = RidgeCV()\n",
    "#rmdl.fit(x_train, y_train)\n",
    "#print(\"10-fold CV R2:\", cross_val_score(rmdl, x_train, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random forest regression\n",
    "#depths = [2,3,5,7,10]\n",
    "#for i in depths:\n",
    "#    fmdl = RandomForestRegressor(n_estimators=100, max_features='sqrt', max_depth=i)\n",
    "#    fmdl.fit(x_train, y_train)\n",
    "#    print(\"10-fold CV R2, depth\", i, \":\", cross_val_score(fmdl, x_train, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: latitude and longitude interaction with state\n",
    "Since restaurants in the dataset in Ontario and Quebec are really just located around Toronto and Montreal, respectively, we can view the coordinates' interaction with a state as an analysis of whether restauraunts in each city get higher ratings the farther west/east/north/south they are located in the city. For randomforest, the decision boundary becomes a literal geographic boundary, dividing the city up into sections and assigning score biases to each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format data\n",
    "x_train = (resids[['state','latitude','longitude']]).copy(deep=True)\n",
    "x_train['QC'] = (x_train.state=='QC')*1\n",
    "x_train['QC_latitude'] = x_train.QC*x_train.latitude\n",
    "x_train['QC_longitude'] = x_train.QC*x_train.longitude\n",
    "x_train = x_train.iloc[:,1:]\n",
    "y_train = resids.resid_of_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold CV R2: -7.91065147508e-05\n"
     ]
    }
   ],
   "source": [
    "# simple linear regression\n",
    "lmdl = LinearRegression()\n",
    "lmdl.fit(x_train, y_train)\n",
    "print(\"10-fold CV R2:\", cross_val_score(lmdl, x_train, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold CV R2: -7.47857359459e-05\n"
     ]
    }
   ],
   "source": [
    "# ridge regression\n",
    "rmdl = RidgeCV()\n",
    "rmdl.fit(x_train, y_train)\n",
    "print(\"10-fold CV R2:\", cross_val_score(rmdl, x_train, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold CV R2, depth 2 : 0.00102056654732\n",
      "10-fold CV R2, depth 3 : 0.00122405998344\n",
      "10-fold CV R2, depth 5 : 0.000980687489795\n",
      "10-fold CV R2, depth 7 : -0.00131674140843\n",
      "10-fold CV R2, depth 10 : -0.0082639210523\n"
     ]
    }
   ],
   "source": [
    "# random forest regression\n",
    "depths = [2,3,5,7,10]\n",
    "for i in depths:\n",
    "    fmdl = RandomForestRegressor(n_estimators=100, max_features='sqrt', max_depth=i)\n",
    "    fmdl.fit(x_train, y_train)\n",
    "    print(\"10-fold CV R2, depth\", i, \":\", cross_val_score(fmdl, x_train, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "We see above that the random forest model (with maximum tree depth of 5) fit on the latitude/longitude data performs the best out of the model tested. We now fit that model as our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = RandomForestRegressor(n_estimators=100, max_features='sqrt', max_depth=5)\n",
    "model3.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict using baseline regression\n",
    "p1 = pd.Series(regress2.predict(holdout_set_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdout_data = holdout_set.copy(deep = True) \n",
    "holdout_subset = holdout_data[['business_id','user_id']]\n",
    "result_holdout = pd.merge(holdout_subset, user_business_residuals, on = ['user_id','business_id'], how = 'inner')\n",
    "result_holdout = result_holdout.merge(business[['business_id','city','state','latitude','longitude']], how='left')\n",
    "holdout_set_x3 = (result_holdout[['state','latitude','longitude']]).copy(deep=True)\n",
    "holdout_set_x3['QC'] = (holdout_set_x3.state=='QC')*1\n",
    "holdout_set_x3['QC_latitude'] = holdout_set_x3.QC*holdout_set_x3.latitude\n",
    "holdout_set_x3['QC_longitude'] = holdout_set_x3.QC*holdout_set_x3.longitude\n",
    "holdout_set_x3 = holdout_set_x3.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p2 = result_holdout['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p3 = model3.predict(holdout_set_x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holdout r^2 for regression model:                                       0.0928745193673\n",
      "holdout r^2 for regression + matrix model:                              0.0928745193673\n",
      "holdout r^2 for regression + matrix + Random Forest regression model:   0.0972615487885\n"
     ]
    }
   ],
   "source": [
    "print('holdout r^2 for regression model:                                      ', r2_score(holdout_set_y, p1))\n",
    "print('holdout r^2 for regression + matrix model:                             ', r2_score(holdout_set_y, p1+p2))\n",
    "print('holdout r^2 for regression + matrix + Random Forest regression model:  ', r2_score(holdout_set_y, p1+p2+p3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1 = pd.Series(regress2.predict(train_set_x))\n",
    "q2 = result_train['residuals_from_mat_factrz']\n",
    "q3 = model3.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training r^2 for regression model:                                       0.269712582918\n",
      "training r^2 for regression + matrix model:                              0.269712582918\n",
      "training r^2 for regression + matrix + Random Forest regression model:   0.27920343767\n"
     ]
    }
   ],
   "source": [
    "print('training r^2 for regression model:                                      ', r2_score(train_set_y, q1))\n",
    "print('training r^2 for regression + matrix model:                             ', r2_score(train_set_y, q1+q2))\n",
    "print('training r^2 for regression + matrix + Random Forest regression model:  ', r2_score(train_set_y, q1+q2+q3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As these results show, the matrix factorization step does not improve the accuracy. On the other hand, the second regression does improve the accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
